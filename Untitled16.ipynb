{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshulchauhan502/btp/blob/main/Untitled16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU:\", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqZjhC-iZHKV",
        "outputId": "9e49bb46-057c-4c36-e850-978277c3d692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJwLQ0cgZgO8",
        "outputId": "29bd721b-6119-46e4-9228-17e3f091a7e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct  3 04:48:05 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_3OmhXDUX9f",
        "outputId": "2b5c2445-9f45-42ff-b283-38030db171c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taqhkATrUWTP",
        "outputId": "1c50d281-7c6d-4b7b-ddfe-ec943b0cfe45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Mixed precision policy: <DTypePolicy \"mixed_float16\">\n",
            "Class distribution:\n",
            " binary_label\n",
            "0    8061\n",
            "1    1954\n",
            "Name: count, dtype: int64\n",
            "Train: 7010, Val: 2013, Test: 992\n",
            "Class weights: {0: 0.6212336051045728, 1: 2.5621345029239766}\n",
            "Epoch 1/5\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 2s/step - accuracy: 0.6815 - auc: 0.7846 - loss: 0.5418 - val_accuracy: 0.7968 - val_auc: 0.8617 - val_loss: 0.4135\n",
            "Epoch 2/5\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 2s/step - accuracy: 0.7575 - auc: 0.8603 - loss: 0.4505 - val_accuracy: 0.7899 - val_auc: 0.8766 - val_loss: 0.4069\n",
            "Epoch 3/5\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 2s/step - accuracy: 0.7462 - auc: 0.8652 - loss: 0.4425 - val_accuracy: 0.7685 - val_auc: 0.8776 - val_loss: 0.4219\n",
            "Epoch 4/5\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 2s/step - accuracy: 0.7575 - auc: 0.8768 - loss: 0.4325 - val_accuracy: 0.8073 - val_auc: 0.8815 - val_loss: 0.3688\n",
            "Epoch 5/5\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 2s/step - accuracy: 0.7815 - auc: 0.8899 - loss: 0.4061 - val_accuracy: 0.7571 - val_auc: 0.8858 - val_loss: 0.4379\n",
            "Epoch 1/5\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m583s\u001b[0m 3s/step - accuracy: 0.5141 - auc: 0.7064 - loss: 0.6810 - val_accuracy: 0.7899 - val_auc: 0.8381 - val_loss: 0.3957\n",
            "Epoch 2/5\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6627 - auc: 0.8051 - loss: 0.5526 - val_accuracy: 0.7909 - val_auc: 0.8308 - val_loss: 0.4123\n",
            "Epoch 3/5\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.7011 - auc: 0.8214 - loss: 0.5254 - val_accuracy: 0.7789 - val_auc: 0.8296 - val_loss: 0.4221\n",
            "Epoch 4/5\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.7223 - auc: 0.8527 - loss: 0.4750 - val_accuracy: 0.7715 - val_auc: 0.8296 - val_loss: 0.4298\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 15s/step - accuracy: 0.8143 - auc: 0.8445 - loss: 0.3819\n",
            "Test Accuracy: 80.44%, Test AUC: 0.8336\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# STEP 1: Centralized Training (EfficientNetB0, HAM10000, Binary Classification)\n",
        "# ================================\n",
        "\n",
        "# ================================\n",
        "# Cell 1: Imports & Setup\n",
        "# ================================\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras import callbacks, mixed_precision\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Enable mixed precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "print(\"Mixed precision policy:\", mixed_precision.global_policy())\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Dataset paths\n",
        "DATA_DIR = \"/content/drive/MyDrive/ham10000_data\"\n",
        "IMG_DIR = os.path.join(DATA_DIR, \"all_images\")\n",
        "META_CSV = os.path.join(DATA_DIR, \"HAM10000_metadata.csv\")\n",
        "\n",
        "# ================================\n",
        "# Cell 2: Load metadata and prepare labels\n",
        "# ================================\n",
        "meta = pd.read_csv(META_CSV)\n",
        "\n",
        "# Create full image paths\n",
        "meta['image_path'] = meta['image_id'].apply(lambda x: os.path.join(IMG_DIR, x + \".jpg\"))\n",
        "\n",
        "# Map diagnosis to binary label\n",
        "benign_labels = [\"nv\", \"bkl\", \"df\", \"vasc\"]\n",
        "malignant_labels = [\"mel\", \"bcc\", \"akiec\"]\n",
        "meta['binary_label'] = meta['dx'].apply(lambda x: 1 if x in malignant_labels else 0)\n",
        "\n",
        "print(\"Class distribution:\\n\", meta['binary_label'].value_counts())\n",
        "\n",
        "# ================================\n",
        "# Cell 3: Train/Val/Test split\n",
        "# ================================\n",
        "train_df, temp_df = train_test_split(meta, test_size=0.3, stratify=meta['binary_label'], random_state=SEED)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.33, stratify=temp_df['binary_label'], random_state=SEED)\n",
        "\n",
        "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
        "\n",
        "# ================================\n",
        "# Cell 4: Dataset pipeline\n",
        "# ================================\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Preprocessing + resize\n",
        "def preprocess(path, label):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "    img = preprocess_input(img)  # EfficientNet preprocessing\n",
        "    return img, label\n",
        "\n",
        "# Data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.RandomRotation(0.06),\n",
        "    tf.keras.layers.RandomZoom(0.08),\n",
        "    tf.keras.layers.RandomTranslation(0.05, 0.05),\n",
        "])\n",
        "\n",
        "def make_dataset(df, training=False):\n",
        "    paths = df['image_path'].values\n",
        "    labels = df['binary_label'].values\n",
        "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
        "    ds = ds.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "    if training:\n",
        "        ds = ds.shuffle(1000, seed=SEED)\n",
        "        ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.batch(BATCH_SIZE)\n",
        "    ds = ds.prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train_ds = make_dataset(train_df, training=True)\n",
        "val_ds = make_dataset(val_df, training=False)\n",
        "test_ds = make_dataset(test_df, training=False)\n",
        "\n",
        "# ================================\n",
        "# Cell 5: Build EfficientNetB0 model\n",
        "# ================================\n",
        "def build_model(base_trainable=False):\n",
        "    base_model = EfficientNetB0(\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "        pooling=None\n",
        "    )\n",
        "    base_model.trainable = base_trainable\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    output = Dense(1, activation=\"sigmoid\", dtype=\"float32\")(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    return model, base_model\n",
        "\n",
        "# ================================\n",
        "# Cell 6: Class weights\n",
        "# ================================\n",
        "classes = np.unique(train_df['binary_label'])\n",
        "weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_df['binary_label'])\n",
        "class_weights_dict = {int(c): float(w) for c, w in zip(classes, weights)}\n",
        "print(\"Class weights:\", class_weights_dict)\n",
        "\n",
        "# ================================\n",
        "# Cell 7: Stage 1 Training (head only)\n",
        "# ================================\n",
        "model, base_model = build_model(base_trainable=False)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")]\n",
        ")\n",
        "\n",
        "EPOCHS_HEAD = 5\n",
        "history_head = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS_HEAD,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)]\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# Cell 8: Stage 2 Training (fine-tune)\n",
        "# ================================\n",
        "# Unfreeze the backbone\n",
        "base_model.trainable = True\n",
        "\n",
        "# Recompile with smaller LR\n",
        "opt_fine = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "model.compile(\n",
        "    optimizer=opt_fine,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")]\n",
        ")\n",
        "\n",
        "EPOCHS_FINE = 5\n",
        "history_fine = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS_FINE,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)]\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# Cell 9: Evaluate on test set\n",
        "# ================================\n",
        "test_loss, test_acc, test_auc = model.evaluate(test_ds)\n",
        "print(f\"Test Accuracy: {test_acc*100:.2f}%, Test AUC: {test_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RACeKnHtb9Vw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM5xICJjqQv/FF+9tR+KLYP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}